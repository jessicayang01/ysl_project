{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead5a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f4ef16",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'YSL_export_16096040.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m YSL_export_16096040 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYSL_export_16096040.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m YSL_export2_16096121 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYSL_export2_16096121.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'YSL_export_16096040.csv'"
     ]
    }
   ],
   "source": [
    "YSL_export_16096040 = pd.read_csv(\"YSL_export_16096040.csv\")\n",
    "YSL_export2_16096121 = pd.read_csv(\"YSL_export2_16096121.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a21367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åˆå¹¶å®Œæˆï¼Œå…± 515791 æ¡æ•°æ®ã€‚\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(\n",
    "    [YSL_export_16096040, YSL_export2_16096121],\n",
    "    axis=0,         # æŒ‰è¡Œæ‹¼æ¥\n",
    "    ignore_index=True  # é‡æ–°ç”Ÿæˆç´¢å¼•\n",
    ")\n",
    "print(f\"âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(df)} æ¡æ•°æ®ã€‚\")\n",
    "df.to_csv(\"/root/ysl_project/df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df[[\"id\", \"url\", \"æ ‡é¢˜\", \"å†…å®¹\", \"è¯é¢˜\", \"å‘è¡¨æ—¶é—´\", \"æ€»äº’åŠ¨é‡\", \"è½¬å‘æ•°\", \"è¯„è®ºæ•°\", \"ç‚¹èµæ•°\", \"æ”¶è—æ•°\", \"ç”¨æˆ·id\", \"å°çº¢ä¹¦å·\", \"ç”¨æˆ·å±åœ°\", \"æ€§åˆ«\", \"å‡ºç”Ÿå¹´ä»½\", \"å…³é”®è¯\", \"ç”¨æˆ·åœ°å€\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38694/3409648221.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df[\"å®Œæ•´å†…å®¹\"] = (\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ æ‹¼æ¥å†…å®¹ã€è¯é¢˜ã€å…³é”®è¯ â†’ æ–°åˆ— â€œå®Œæ•´å†…å®¹â€\n",
    "cleaned_df[\"å®Œæ•´å†…å®¹\"] = (\n",
    "    cleaned_df[\"å†…å®¹\"].fillna(\"\") + \"ã€‚\" +\n",
    "    \"è¯é¢˜ï¼š\" + cleaned_df[\"è¯é¢˜\"].fillna(\"\") + \"ã€‚\" +\n",
    "    \"å…³é”®è¯ï¼š\" + cleaned_df[\"å…³é”®è¯\"].fillna(\"\")\n",
    ").str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061e4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ–‡æœ¬æ¸…æ´—å®Œæˆï¼ç¤ºä¾‹ï¼š\n",
      "                                                       å†…å®¹  \\\n",
      "0       Yå®¶çš„éº‚çš®æ£•é…ä¸Šå¤§è¡£å’Œæ¯›è¡£çœŸçš„é«˜çº§æ¾å¼›æ„Ÿæ‹‰æ»¡ï½ åŒ…èº«é‡‡ç”¨å¥¢åè½»ä¾¿è±å½¢ç»—ç¼æ˜çº¿ï¼Œé¥±æ»¡ä¸æ»‘ï¼Œè§¦æ„Ÿ...   \n",
      "1       #yslåœ£ç½—å…° #YSLåœ£ç½—å…° #åœ£ç½—å…° #è¿ä½“è£¤ #è®¾è®¡æ„Ÿè¿è¡£è£™ #éœ²èƒŒè£… #å°é»‘è£™ #éœ²...   \n",
      "2       YSLæ¿æå¾®ç¿˜çŒ«çœ¼æ¬¾ğŸ•¶ï¸ æ¿æå‰æ¡†åŠ ä¸Šé‡‘å±é•œè…¿ï¼Œysläº¤ç»‡logo é•œç‰‡æ¸å˜è‰²ï¼Œè¶…çº§å¥½çœ‹æ—¶å°š...   \n",
      "3       #ysl #è¶…æ¨¡ #éª¨å­é‡Œçš„ä¼˜é›… #æ—¶å°šå¥³é­”å¤´ #æ—¶å°š #æ—¶å°šç•Œå® å„¿ #æ—¶å°šèµ„è®¯ #å¯»æ‰¾ç§€åœº...   \n",
      "4       yslå…¨å“ç±»å‚åŠ æ´»åŠ¨ï¼Œ åŠ›åº¦å¼€åº—ä»¥æ¥æœ€å¤§ä¸€æ¬¡ æŠ“ä½æœºä¼šå“¦ #ysl #æ–°æ¬¾åˆ†äº« #skpæ´»åŠ¨...   \n",
      "...                                                   ...   \n",
      "515786  åæ‚”æ²¡æ—©ç‚¹å…¥ï¼Œä¸Šèº«çœŸçš„å¤ªå¥½çœ‹å®ç”¨å•¦ï¼Œè™½ç„¶åŒ…åŒ…æ˜¯æ›¿æ›¿ï¼Œä½†æ—¥å¸¸ä½¿ç”¨è¶…æ»¡è¶³#ysl #yslåœ£ç½—å…°...   \n",
      "515787                  æ²¡æœ‰å¥³å­©å­èƒ½æŠ—æ‹’ä¸€åªé“¶è‰²çš„YSL #åœ£ç½—å…° #ä¸­å¤åŒ…vintage   \n",
      "515788  #åŒ…åŒ…åˆ†äº« #åŒ…åŒ…ä¸é‡æ · #æœ€çˆ±çš„åŒ…åŒ… #yslåŒ…åŒ… #ysl #yslåœ£ç½—å…° #YSLåœ£ç½—...   \n",
      "515789                                            #ç•™å­¦ #uk   \n",
      "515790  å‰å‰ååå»è¯•äº†jimmychoo/Christian Louboutin/ Roger Vi...   \n",
      "\n",
      "                         æ ‡é¢˜                                               å®Œæ•´å†…å®¹  \n",
      "0         æ¥äº†ï½œç§‹å¤©å¾—å¿…å¤‡éº‚çš®ğˆğ‚ğ€ğ‘ğˆğğ  Yå®¶çš„éº‚çš®æ£•é…ä¸Šå¤§è¡£å’Œæ¯›è¡£çœŸçš„é«˜çº§æ¾å¼›æ„Ÿæ‹‰æ»¡ï½ åŒ…èº«é‡‡ç”¨å¥¢åè½»ä¾¿è±å½¢ç»—ç¼æ˜çº¿ï¼Œé¥±æ»¡ä¸æ»‘ï¼Œè§¦æ„Ÿ...  \n",
      "1                     éœ²èƒŒè¿ä½“è£¤  #yslåœ£ç½—å…° #YSLåœ£ç½—å…° #åœ£ç½—å…° #è¿ä½“è£¤ #è®¾è®¡æ„Ÿè¿è¡£è£™ #éœ²èƒŒè£… #å°é»‘è£™ #éœ²...  \n",
      "2               YSLÂ·æ½®æµç™¾æ­æ¬¾ğŸ•¶ï¸  YSLæ¿æå¾®ç¿˜çŒ«çœ¼æ¬¾ğŸ•¶ï¸ æ¿æå‰æ¡†åŠ ä¸Šé‡‘å±é•œè…¿ï¼Œysläº¤ç»‡logo é•œç‰‡æ¸å˜è‰²ï¼Œè¶…çº§å¥½çœ‹æ—¶å°š...  \n",
      "3         BELLA HADID INåœ£ç½—å…°  #ysl #è¶…æ¨¡ #éª¨å­é‡Œçš„ä¼˜é›… #æ—¶å°šå¥³é­”å¤´ #æ—¶å°š #æ—¶å°šç•Œå® å„¿ #æ—¶å°šèµ„è®¯ #å¯»æ‰¾ç§€åœº...  \n",
      "4             å¬è¯´SKPæ‰€æœ‰å“ç±»æ‰“éª¨æŠ˜ï¼Ÿ  yslå…¨å“ç±»å‚åŠ æ´»åŠ¨ï¼Œ åŠ›åº¦å¼€åº—ä»¥æ¥æœ€å¤§ä¸€æ¬¡ æŠ“ä½æœºä¼šå“¦ #ysl #æ–°æ¬¾åˆ†äº« #skpæ´»åŠ¨...  \n",
      "...                     ...                                                ...  \n",
      "515786  YSL hoboçœŸå®ä½¿ç”¨åé¦ˆ|åæ‚”äº†ğŸ˜­  åæ‚”æ²¡æ—©ç‚¹å…¥ï¼Œä¸Šèº«çœŸçš„å¤ªå¥½çœ‹å®ç”¨å•¦ï¼Œè™½ç„¶åŒ…åŒ…æ˜¯æ›¿æ›¿ï¼Œä½†æ—¥å¸¸ä½¿ç”¨è¶…æ»¡è¶³#ysl #yslåœ£ç½—å…°...  \n",
      "515787       38åº¦çš„å¤©æ°”å½“ç„¶è¦èƒŒé“¶è‰²å°åŒ…  æ²¡æœ‰å¥³å­©å­èƒ½æŠ—æ‹’ä¸€åªé“¶è‰²çš„YSL #åœ£ç½—å…° #ä¸­å¤åŒ…vintageã€‚è¯é¢˜ï¼šåœ£ç½—å…°|ä¸­å¤åŒ…vi...  \n",
      "515788           YSLäº‘æœµåŒ…å¼€ç®±åˆ†äº«  #åŒ…åŒ…åˆ†äº« #åŒ…åŒ…ä¸é‡æ · #æœ€çˆ±çš„åŒ…åŒ… #yslåŒ…åŒ… #ysl #yslåœ£ç½—å…° #YSLåœ£ç½—...  \n",
      "515789   â€¼ï¸â€¼ï¸â€¼ï¸Yslå¡åŒ…è¡¥è´§ï¼Œç°è´§ç§’å‘                   #ç•™å­¦ #ukã€‚è¯é¢˜ï¼šç•™å­¦|ukã€‚å…³é”®è¯ï¼šå¡åŒ…|è¡¥è´§|ç°è´§|ç•™å­¦  \n",
      "515790         å¤‡å©š2.0 å’ŒRCé”æ­»äº†  å‰å‰ååå»è¯•äº†jimmychoo/Christian Louboutin/ Roger Vi...  \n",
      "\n",
      "[515791 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text_minimal(text: str) -> str:\n",
    "    \"\"\"åˆ é™¤ emoji å’Œé‚®ç®±\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    s = str(text)\n",
    "\n",
    "    # å»é‚®ç®±\n",
    "    s = re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', '', s)\n",
    "\n",
    "    # å» emojiï¼ˆåŒ¹é…æ‰€æœ‰éBMPè¡¨æƒ…ç¬¦å·ï¼‰\n",
    "    emoji_pattern = re.compile(\"[\\U00010000-\\U0010FFFF]\", flags=re.UNICODE)\n",
    "    s = emoji_pattern.sub(\"\", s)\n",
    "\n",
    "    return s.strip()\n",
    "\n",
    "# ç¤ºä¾‹åº”ç”¨\n",
    "text_cols = [\"å†…å®¹\",\"æ ‡é¢˜\", \"å®Œæ•´å†…å®¹\"]  # ä½ è¦æ¸…æ´—çš„åˆ—å\n",
    "for col in text_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_text_minimal)\n",
    "\n",
    "print(\"âœ… æ–‡æœ¬æ¸…æ´—å®Œæˆï¼ç¤ºä¾‹ï¼š\")\n",
    "print(cleaned_df[text_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391de867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŸå§‹è¡Œæ•°: 515791\n",
      "âœ… ä¿ç•™è¡Œæ•°: 493843\n",
      "ğŸ“‰ åˆ é™¤æ¯”ä¾‹: 4.26%\n"
     ]
    }
   ],
   "source": [
    "# 1ï¸âƒ£ è®¡ç®—æ€»è¡Œæ•°\n",
    "total_rows = len(cleaned_df)\n",
    "\n",
    "# 2ï¸âƒ£ è¿‡æ»¤æ‰å†…å®¹é•¿åº¦å°äº 15 çš„è¡Œ\n",
    "cleaned_df = cleaned_df[cleaned_df['å†…å®¹'].astype(str).str.len() >= 15].copy()\n",
    "\n",
    "# 3ï¸âƒ£ è®¡ç®—è¢«åˆ æ‰çš„æ¯”ä¾‹\n",
    "removed_ratio = 1 - len(cleaned_df) / total_rows\n",
    "\n",
    "print(f\"âœ… åŸå§‹è¡Œæ•°: {total_rows}\")\n",
    "print(f\"âœ… ä¿ç•™è¡Œæ•°: {len(cleaned_df)}\")\n",
    "print(f\"ğŸ“‰ åˆ é™¤æ¯”ä¾‹: {removed_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c589bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  å†…å®¹  \\\n",
      "0  Yå®¶çš„éº‚çš®æ£•é…ä¸Šå¤§è¡£å’Œæ¯›è¡£çœŸçš„é«˜çº§æ¾å¼›æ„Ÿæ‹‰æ»¡ï½ åŒ…èº«é‡‡ç”¨å¥¢åè½»ä¾¿è±å½¢ç»—ç¼æ˜çº¿ï¼Œé¥±æ»¡ä¸æ»‘ï¼Œè§¦æ„Ÿ...   \n",
      "1  #yslåœ£ç½—å…° #YSLåœ£ç½—å…° #åœ£ç½—å…° #è¿ä½“è£¤ #è®¾è®¡æ„Ÿè¿è¡£è£™ #éœ²èƒŒè£… #å°é»‘è£™ #éœ²...   \n",
      "2  YSLæ¿æå¾®ç¿˜çŒ«çœ¼æ¬¾ğŸ•¶ï¸ æ¿æå‰æ¡†åŠ ä¸Šé‡‘å±é•œè…¿ï¼Œysläº¤ç»‡logo é•œç‰‡æ¸å˜è‰²ï¼Œè¶…çº§å¥½çœ‹æ—¶å°š...   \n",
      "3  #ysl #è¶…æ¨¡ #éª¨å­é‡Œçš„ä¼˜é›… #æ—¶å°šå¥³é­”å¤´ #æ—¶å°š #æ—¶å°šç•Œå® å„¿ #æ—¶å°šèµ„è®¯ #å¯»æ‰¾ç§€åœº...   \n",
      "4  yslå…¨å“ç±»å‚åŠ æ´»åŠ¨ï¼Œ åŠ›åº¦å¼€åº—ä»¥æ¥æœ€å¤§ä¸€æ¬¡ æŠ“ä½æœºä¼šå“¦ #ysl #æ–°æ¬¾åˆ†äº« #skpæ´»åŠ¨...   \n",
      "\n",
      "                                                å®Œæ•´å†…å®¹  \\\n",
      "0  Yå®¶çš„éº‚çš®æ£•é…ä¸Šå¤§è¡£å’Œæ¯›è¡£çœŸçš„é«˜çº§æ¾å¼›æ„Ÿæ‹‰æ»¡ï½ åŒ…èº«é‡‡ç”¨å¥¢åè½»ä¾¿è±å½¢ç»—ç¼æ˜çº¿ï¼Œé¥±æ»¡ä¸æ»‘ï¼Œè§¦æ„Ÿ...   \n",
      "1  #yslåœ£ç½—å…° #YSLåœ£ç½—å…° #åœ£ç½—å…° #è¿ä½“è£¤ #è®¾è®¡æ„Ÿè¿è¡£è£™ #éœ²èƒŒè£… #å°é»‘è£™ #éœ²...   \n",
      "2  YSLæ¿æå¾®ç¿˜çŒ«çœ¼æ¬¾ğŸ•¶ï¸ æ¿æå‰æ¡†åŠ ä¸Šé‡‘å±é•œè…¿ï¼Œysläº¤ç»‡logo é•œç‰‡æ¸å˜è‰²ï¼Œè¶…çº§å¥½çœ‹æ—¶å°š...   \n",
      "3  #ysl #è¶…æ¨¡ #éª¨å­é‡Œçš„ä¼˜é›… #æ—¶å°šå¥³é­”å¤´ #æ—¶å°š #æ—¶å°šç•Œå® å„¿ #æ—¶å°šèµ„è®¯ #å¯»æ‰¾ç§€åœº...   \n",
      "4  yslå…¨å“ç±»å‚åŠ æ´»åŠ¨ï¼Œ åŠ›åº¦å¼€åº—ä»¥æ¥æœ€å¤§ä¸€æ¬¡ æŠ“ä½æœºä¼šå“¦ #ysl #æ–°æ¬¾åˆ†äº« #skpæ´»åŠ¨...   \n",
      "\n",
      "                                            å®Œæ•´å†…å®¹_æ¸…ç†å  \\\n",
      "0  Yå®¶çš„éº‚çš®æ£•é…ä¸Šå¤§è¡£å’Œæ¯›è¡£çœŸçš„é«˜çº§æ¾å¼›æ„Ÿæ‹‰æ»¡ åŒ…èº«é‡‡ç”¨å¥¢åè½»ä¾¿è±å½¢ç»—ç¼æ˜çº¿é¥±æ»¡ä¸æ»‘è§¦æ„Ÿç»†è…»è½¯...   \n",
      "1  yslåœ£ç½—å…° YSLåœ£ç½—å…° åœ£ç½—å…° è¿ä½“è£¤ è®¾è®¡æ„Ÿè¿è¡£è£™ éœ²èƒŒè£… å°é»‘è£™ éœ²èƒŒè£™ æ°”è´¨å°é»‘è£™...   \n",
      "2  YSLæ¿æå¾®ç¿˜çŒ«çœ¼æ¬¾ æ¿æå‰æ¡†åŠ ä¸Šé‡‘å±é•œè…¿ysläº¤ç»‡logo é•œç‰‡æ¸å˜è‰²è¶…çº§å¥½çœ‹æ—¶å°š äºšæ´²ç‰ˆ...   \n",
      "3  ysl è¶…æ¨¡ éª¨å­é‡Œçš„ä¼˜é›… æ—¶å°šå¥³é­”å¤´ æ—¶å°š æ—¶å°šç•Œå® å„¿ æ—¶å°šèµ„è®¯ å¯»æ‰¾ç§€åœºä¸Šçš„ç¾ åœ£ç½—å…° ...   \n",
      "4  yslå…¨å“ç±»å‚åŠ æ´»åŠ¨ åŠ›åº¦å¼€åº—ä»¥æ¥æœ€å¤§ä¸€æ¬¡ æŠ“ä½æœºä¼šå“¦ ysl æ–°æ¬¾åˆ†äº« skpæ´»åŠ¨ SKP...   \n",
      "\n",
      "                                                åˆå¹¶å†…å®¹  \n",
      "0  æ¥äº†ï½œç§‹å¤©å¾—å¿…å¤‡éº‚çš®ğˆğ‚ğ€ğ‘ğˆğğ Yå®¶çš„éº‚çš®æ£•é…ä¸Šå¤§è¡£å’Œæ¯›è¡£çœŸçš„é«˜çº§æ¾å¼›æ„Ÿæ‹‰æ»¡ åŒ…èº«é‡‡ç”¨å¥¢...  \n",
      "1  éœ²èƒŒè¿ä½“è£¤ yslåœ£ç½—å…° YSLåœ£ç½—å…° åœ£ç½—å…° è¿ä½“è£¤ è®¾è®¡æ„Ÿè¿è¡£è£™ éœ²èƒŒè£… å°é»‘è£™ éœ²èƒŒè£™...  \n",
      "2  YSLÂ·æ½®æµç™¾æ­æ¬¾ğŸ•¶ï¸ YSLæ¿æå¾®ç¿˜çŒ«çœ¼æ¬¾ æ¿æå‰æ¡†åŠ ä¸Šé‡‘å±é•œè…¿ysläº¤ç»‡logo é•œç‰‡æ¸...  \n",
      "3  BELLA HADID INåœ£ç½—å…° ysl è¶…æ¨¡ éª¨å­é‡Œçš„ä¼˜é›… æ—¶å°šå¥³é­”å¤´ æ—¶å°š æ—¶å°šç•Œå® å„¿...  \n",
      "4  å¬è¯´SKPæ‰€æœ‰å“ç±»æ‰“éª¨æŠ˜ï¼Ÿ yslå…¨å“ç±»å‚åŠ æ´»åŠ¨ åŠ›åº¦å¼€åº—ä»¥æ¥æœ€å¤§ä¸€æ¬¡ æŠ“ä½æœºä¼šå“¦ ysl ...  \n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼šå»é™¤æ ‡ç‚¹ç¬¦å·ã€ç‰¹æ®Šå­—ç¬¦\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # å»æ‰æ‰€æœ‰ä¸­æ–‡ã€è‹±æ–‡æ ‡ç‚¹ç¬¦å·ã€è¡¨æƒ…ã€ç‰¹æ®Šç¬¦å·ï¼Œåªä¿ç•™ä¸­è‹±æ–‡ã€æ•°å­—å’Œç©ºæ ¼\n",
    "    text = re.sub(r'[^\\w\\s\\u4e00-\\u9fff]', '', str(text))\n",
    "    # å»é™¤å¤šä½™ç©ºæ ¼\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# 2ï¸âƒ£ æ¸…ç†â€œå®Œæ•´å†…å®¹â€åˆ—\n",
    "cleaned_df['å®Œæ•´å†…å®¹_æ¸…ç†å'] = cleaned_df['å®Œæ•´å†…å®¹'].apply(clean_text)\n",
    "\n",
    "# 3ï¸âƒ£ åˆå¹¶â€œå†…å®¹â€å’Œæ¸…ç†åçš„â€œå®Œæ•´å†…å®¹â€\n",
    "cleaned_df['åˆå¹¶å†…å®¹'] = cleaned_df['æ ‡é¢˜'].fillna('') + ' ' + cleaned_df['å®Œæ•´å†…å®¹_æ¸…ç†å']\n",
    "\n",
    "# 4ï¸âƒ£ å†æ¬¡æ¸…ç†åˆå¹¶åçš„æ–‡æœ¬ï¼ˆé˜²æ­¢é‡å¤æ ‡ç‚¹æˆ–ç©ºæ ¼ï¼‰\n",
    "cleaned_df['åˆå¹¶å†…å®¹'] = cleaned_df['åˆå¹¶å†…å®¹'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "# 5ï¸âƒ£ è¾“å‡ºç»“æœ\n",
    "print(cleaned_df[['å†…å®¹', 'å®Œæ•´å†…å®¹', 'å®Œæ•´å†…å®¹_æ¸…ç†å', 'åˆå¹¶å†…å®¹']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv(\"cleaned_df_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b03dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å„åˆ—ç¼ºå¤±æƒ…å†µï¼š\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ç¼ºå¤±æ¯”ä¾‹</th>\n",
       "      <th>éç©ºæ¯”ä¾‹</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>å‡ºç”Ÿå¹´ä»½</th>\n",
       "      <td>93.19%</td>\n",
       "      <td>6.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ç”¨æˆ·åœ°å€</th>\n",
       "      <td>49.2%</td>\n",
       "      <td>50.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æ€§åˆ«</th>\n",
       "      <td>43.04%</td>\n",
       "      <td>56.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ç”¨æˆ·å±åœ°</th>\n",
       "      <td>32.43%</td>\n",
       "      <td>67.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>è½¬å‘æ•°</th>\n",
       "      <td>29.77%</td>\n",
       "      <td>70.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æ”¶è—æ•°</th>\n",
       "      <td>29.67%</td>\n",
       "      <td>70.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>è¯„è®ºæ•°</th>\n",
       "      <td>28.48%</td>\n",
       "      <td>71.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>å°çº¢ä¹¦å·</th>\n",
       "      <td>15.41%</td>\n",
       "      <td>84.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>è¯é¢˜</th>\n",
       "      <td>7.8%</td>\n",
       "      <td>92.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æ ‡é¢˜</th>\n",
       "      <td>3.45%</td>\n",
       "      <td>96.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ç‚¹èµæ•°</th>\n",
       "      <td>0.11%</td>\n",
       "      <td>99.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>å…³é”®è¯</th>\n",
       "      <td>0.01%</td>\n",
       "      <td>99.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>å®Œæ•´å†…å®¹_æ¸…ç†å</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>å®Œæ•´å†…å®¹</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ç”¨æˆ·id</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æ€»äº’åŠ¨é‡</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>å‘è¡¨æ—¶é—´</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>å†…å®¹</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ç¼ºå¤±æ¯”ä¾‹    éç©ºæ¯”ä¾‹\n",
       "å‡ºç”Ÿå¹´ä»½      93.19%   6.81%\n",
       "ç”¨æˆ·åœ°å€       49.2%   50.8%\n",
       "æ€§åˆ«        43.04%  56.96%\n",
       "ç”¨æˆ·å±åœ°      32.43%  67.57%\n",
       "è½¬å‘æ•°       29.77%  70.23%\n",
       "æ”¶è—æ•°       29.67%  70.33%\n",
       "è¯„è®ºæ•°       28.48%  71.52%\n",
       "å°çº¢ä¹¦å·      15.41%  84.59%\n",
       "è¯é¢˜          7.8%   92.2%\n",
       "æ ‡é¢˜         3.45%  96.55%\n",
       "ç‚¹èµæ•°        0.11%  99.89%\n",
       "å…³é”®è¯        0.01%  99.99%\n",
       "å®Œæ•´å†…å®¹_æ¸…ç†å    0.0%  100.0%\n",
       "å®Œæ•´å†…å®¹        0.0%  100.0%\n",
       "id          0.0%  100.0%\n",
       "ç”¨æˆ·id        0.0%  100.0%\n",
       "url         0.0%  100.0%\n",
       "æ€»äº’åŠ¨é‡        0.0%  100.0%\n",
       "å‘è¡¨æ—¶é—´        0.0%  100.0%\n",
       "å†…å®¹          0.0%  100.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# è®¡ç®—æ¯åˆ—ç©ºå€¼æ¯”ä¾‹\n",
    "null_summary = (\n",
    "    cleaned_df.isna()\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame(\"ç¼ºå¤±æ¯”ä¾‹\")\n",
    "    .assign(éç©ºæ¯”ä¾‹=lambda x: 1 - x[\"ç¼ºå¤±æ¯”ä¾‹\"])\n",
    ")\n",
    "\n",
    "# è½¬æ¢ä¸ºç™¾åˆ†æ¯”æ˜¾ç¤º\n",
    "null_summary[\"ç¼ºå¤±æ¯”ä¾‹\"] = (null_summary[\"ç¼ºå¤±æ¯”ä¾‹\"] * 100).round(2).astype(str) + \"%\"\n",
    "null_summary[\"éç©ºæ¯”ä¾‹\"] = (null_summary[\"éç©ºæ¯”ä¾‹\"] * 100).round(2).astype(str) + \"%\"\n",
    "\n",
    "print(\"âœ… å„åˆ—ç¼ºå¤±æƒ…å†µï¼š\")\n",
    "display(null_summary.head(20))  # æ˜¾ç¤ºå‰ 20 åˆ—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027133f0",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b1f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== ğŸ§¾ Dataset Overview ====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.unicode_minus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==== ğŸ§¾ Dataset Overview ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal rows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cleaned_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cleaned_df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 1ï¸âƒ£ ID Uniqueness\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# =============================\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_df' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# âœ… ç¡®ä¿ä¸­æ–‡å¯æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['PingFang SC', 'Microsoft YaHei', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"==== ğŸ§¾ Dataset Overview ====\")\n",
    "print(f\"Total rows: {len(cleaned_df)}\")\n",
    "print(f\"Total columns: {len(cleaned_df.columns)}\\n\")\n",
    "\n",
    "# =============================\n",
    "# 1ï¸âƒ£ ID Uniqueness\n",
    "# =============================\n",
    "total = len(cleaned_df)\n",
    "unique = cleaned_df['post_id'].nunique()\n",
    "duplicates = total - unique\n",
    "print(f\"ğŸ†” ID Uniqueness Check: Total {total}, Unique IDs {unique}, Duplicates {duplicates}.\")\n",
    "if duplicates > 0:\n",
    "    dup_ids = cleaned_df['post_id'].value_counts().loc[lambda x: x > 1]\n",
    "    print(\"âš ï¸ Example of Duplicate IDs:\\n\", dup_ids.head())\n",
    "\n",
    "# =============================\n",
    "# 2ï¸âƒ£ Post Time Distribution\n",
    "# =============================\n",
    "if 'post_time' in cleaned_df.columns:\n",
    "    cleaned_df['post_time'] = pd.to_datetime(cleaned_df['post_time'], errors='coerce')\n",
    "    print(\"\\nğŸ•’ Post Time Range:\")\n",
    "    print(f\"Earliest: {cleaned_df['post_time'].min()}  Latest: {cleaned_df['post_time'].max()}\")\n",
    "    print(\"ğŸ“ˆ Posts per Month:\")\n",
    "    cleaned_df['Month'] = cleaned_df['post_time'].dt.to_period('M')\n",
    "    post_counts = cleaned_df['Month'].value_counts().sort_index()\n",
    "    display(post_counts.head(10))\n",
    "    plt.figure(figsize=(10,4))\n",
    "    post_counts.plot(kind='bar', color='teal', title='Monthly Post Count')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Number of Posts')\n",
    "    plt.show()\n",
    "\n",
    "# =============================\n",
    "# 3ï¸âƒ£ Engagement Metrics with Outlier Handling\n",
    "# =============================\n",
    "\n",
    "eng_col_map = {\n",
    "    'interaction_times': 'Interaction Times',\n",
    "    'shares': 'Shares',\n",
    "    'comments': 'Comments',\n",
    "    'likes': 'Likes',\n",
    "    'saves': 'Saves'\n",
    "}\n",
    "\n",
    "def plot_with_outlier_split(df, col):\n",
    "    if col not in df.columns:\n",
    "        print(f\"âš ï¸ Column {col} not found.\")\n",
    "        return\n",
    "    if not np.issubdtype(df[col].dropna().dtype, np.number):\n",
    "        print(f\"âš ï¸ Column {col} is not numeric, skipping.\")\n",
    "        return\n",
    "\n",
    "    col_en = eng_col_map.get(col, col)\n",
    "    q95 = df[col].quantile(0.95)\n",
    "    qmax = df[col].max()\n",
    "    num_outliers = (df[col] > q95).sum()\n",
    "\n",
    "    print(f\"\\nğŸ“Š {col_en} Distribution:\")\n",
    "    print(f\"95th percentile = {q95:.2f}, max = {qmax:.2f}, outliers = {num_outliers} ({num_outliers/len(df)*100:.2f}%)\")\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df[df[col] <= q95][col], bins=50, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'{col_en} Distribution (â‰¤ 95th percentile)')\n",
    "    plt.xlabel(col_en)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    if num_outliers > 0:\n",
    "        plt.figure(figsize=(5,3))\n",
    "        sns.boxplot(x=df[df[col] > q95][col], color='salmon')\n",
    "        plt.title(f'{col_en} Outliers (>95th percentile)')\n",
    "        plt.xlabel(col_en)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"âœ… No outliers beyond 95th percentile for {col_en}\")\n",
    "\n",
    "engagement_cols = ['interaction_times', 'shares', 'comments', 'likes', 'saves']\n",
    "for col in engagement_cols:\n",
    "    if col in cleaned_df.columns:\n",
    "        plot_with_outlier_split(cleaned_df, col)\n",
    "\n",
    "# =============================\n",
    "# 4ï¸âƒ£ User Location Distribution\n",
    "# =============================\n",
    "if 'user_location' in cleaned_df.columns:\n",
    "    top_location = cleaned_df['user_location'].value_counts(dropna=True).head(10)\n",
    "    print(\"\\nğŸŒ Top 10 User Locations:\")\n",
    "    display(top_location)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    top_location.plot(kind='bar', color='coral')\n",
    "    plt.title('Top 10 User Locations')\n",
    "    plt.xlabel('Region')\n",
    "    plt.ylabel('User Count')\n",
    "    plt.show()\n",
    "\n",
    "# =============================\n",
    "# 5ï¸âƒ£ Gender Distribution\n",
    "# =============================\n",
    "if 'gender' in cleaned_df.columns:\n",
    "    print(\"\\nğŸš» Gender Distribution:\")\n",
    "\n",
    "    cleaned_df['gender'] = cleaned_df['gender'].fillna('Unknown')\n",
    "    cleaned_df.loc[cleaned_df['gender'].isin(['æœªçŸ¥', 'æœªå¡«å†™', 'ä¸æ˜', 'Unknown']), 'gender'] = 'Unknown'\n",
    "\n",
    "    gender_counts = cleaned_df['gender'].value_counts(dropna=False)\n",
    "    display(gender_counts)\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    gender_counts.plot(kind='pie', autopct='%.1f%%', colors=['pink','lightblue','gray'])\n",
    "    plt.title('Gender Distribution')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "\n",
    "# =============================\n",
    "# 6ï¸âƒ£ Birth Year Distribution (showing middle 90% + outliers)\n",
    "# =============================\n",
    "if 'birth_year' in cleaned_df.columns:\n",
    "    print(\"\\nğŸ‘¶ Birth Year Distribution (with outlier visualization):\")\n",
    "    \n",
    "    cleaned_df['birth_year'] = pd.to_numeric(cleaned_df['birth_year'], errors='coerce')\n",
    "    birth_series = cleaned_df['birth_year'].dropna()\n",
    "\n",
    "    q0025 = birth_series.quantile(0.025)\n",
    "    q0975 = birth_series.quantile(0.975)\n",
    "\n",
    "    lower_outliers = birth_series[birth_series < q0025]\n",
    "    middle_values = birth_series[(birth_series >= q0025) & (birth_series <= q0975)]\n",
    "    upper_outliers = birth_series[birth_series > q0975]\n",
    "\n",
    "    print(f\"2.5th percentile = {q0025:.0f}, 97.5th percentile = {q0975:.0f}\")\n",
    "    print(f\"Lower outliers: {len(lower_outliers)} ({len(lower_outliers)/len(birth_series)*100:.2f}%)\")\n",
    "    print(f\"Upper outliers: {len(upper_outliers)} ({len(upper_outliers)/len(birth_series)*100:.2f}%)\")\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(middle_values, bins=30, color='gold', edgecolor='black')\n",
    "    plt.title('Birth Year Distribution (Middle 95%)')\n",
    "    plt.xlabel('Birth Year')\n",
    "    plt.ylabel('User Count')\n",
    "    plt.show()\n",
    "\n",
    "    if len(lower_outliers) > 0:\n",
    "        plt.figure(figsize=(5,3))\n",
    "        sns.boxplot(x=lower_outliers, color='skyblue')\n",
    "        plt.title('Lower 5% Birth Year Outliers')\n",
    "        plt.xlabel('Birth Year')\n",
    "        plt.show()\n",
    "\n",
    "    if len(upper_outliers) > 0:\n",
    "        plt.figure(figsize=(5,3))\n",
    "        sns.boxplot(x=upper_outliers, color='salmon')\n",
    "        plt.title('Upper 5% Birth Year Outliers')\n",
    "        plt.xlabel('Birth Year')\n",
    "        plt.show()\n",
    "\n",
    "# =============================\n",
    "# 7ï¸âƒ£ User Address Samples\n",
    "# =============================\n",
    "if 'user_address' in cleaned_df.columns:\n",
    "    print(\"\\nğŸ  User Address Samples:\")\n",
    "    sample_addr = cleaned_df['user_address'].dropna().head(10)\n",
    "    print(sample_addr)\n",
    "    print(f\"Non-null ratio: {(cleaned_df['user_address'].notna().mean()*100):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
