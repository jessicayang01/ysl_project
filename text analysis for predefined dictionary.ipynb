{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363cf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Collecting jieba\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m154.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=2b36fa871dcf16d594937d801083d6a815a4f5d367aad61d3a801e9145d96288\n",
      "  Stored in directory: /root/.cache/pip/wheels/da/3f/b4/b354c16356473a3aea055b30d107034d9f45b87e25630f1357\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a099aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "833075f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title_content_hashtag_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>æ¥äº†ï½œç§‹å¤©å¾—å¿…å¤‡éº‚çš®ğˆğ‚ğ€ğ‘ğˆğğã€‚å†…å®¹ï¼šYå®¶çš„éº‚çš®æ£•é…ä¸Šå¤§è¡£å’Œæ¯›è¡£çœŸçš„é«˜çº§æ¾å¼›æ„Ÿæ‹‰æ»¡ï½ åŒ…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>YSLÂ·æ½®æµç™¾æ­æ¬¾ğŸ•¶ï¸ã€‚å†…å®¹ï¼šYSLæ¿æå¾®ç¿˜çŒ«çœ¼æ¬¾ğŸ•¶ï¸ æ¿æå‰æ¡†åŠ ä¸Šé‡‘å±é•œè…¿ï¼Œysläº¤ç»‡lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BELLA HADID INåœ£ç½—å…°ã€‚å†…å®¹ï¼š#ysl #è¶…æ¨¡ #éª¨å­é‡Œçš„ä¼˜é›… #æ—¶å°šå¥³é­”å¤´ #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>å¬è¯´SKPæ‰€æœ‰å“ç±»æ‰“éª¨æŠ˜ï¼Ÿã€‚å†…å®¹ï¼šyslå…¨å“ç±»å‚åŠ æ´»åŠ¨ï¼Œ åŠ›åº¦å¼€åº—ä»¥æ¥æœ€å¤§ä¸€æ¬¡ æŠ“ä½æœºä¼šå“¦ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>åœ£ç½—å…°å¢¨é•œç³ç‘è‰²çœŸå¥½çœ‹ã€‚å†…å®¹ï¼š#æ˜†æ˜æ’éš†åœ£ç½—å…° #è®¾è®¡æ„Ÿå¢¨é•œ #æ—¶å°šå¤ªé˜³çœ¼é•œ #æ—¶å°šæ½®æµçœ¼é•œ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                      title_content_hashtag_cleaned\n",
       "0      0  æ¥äº†ï½œç§‹å¤©å¾—å¿…å¤‡éº‚çš®ğˆğ‚ğ€ğ‘ğˆğğã€‚å†…å®¹ï¼šYå®¶çš„éº‚çš®æ£•é…ä¸Šå¤§è¡£å’Œæ¯›è¡£çœŸçš„é«˜çº§æ¾å¼›æ„Ÿæ‹‰æ»¡ï½ åŒ…...\n",
       "1      1  YSLÂ·æ½®æµç™¾æ­æ¬¾ğŸ•¶ï¸ã€‚å†…å®¹ï¼šYSLæ¿æå¾®ç¿˜çŒ«çœ¼æ¬¾ğŸ•¶ï¸ æ¿æå‰æ¡†åŠ ä¸Šé‡‘å±é•œè…¿ï¼Œysläº¤ç»‡lo...\n",
       "2      2  BELLA HADID INåœ£ç½—å…°ã€‚å†…å®¹ï¼š#ysl #è¶…æ¨¡ #éª¨å­é‡Œçš„ä¼˜é›… #æ—¶å°šå¥³é­”å¤´ #...\n",
       "3      3  å¬è¯´SKPæ‰€æœ‰å“ç±»æ‰“éª¨æŠ˜ï¼Ÿã€‚å†…å®¹ï¼šyslå…¨å“ç±»å‚åŠ æ´»åŠ¨ï¼Œ åŠ›åº¦å¼€åº—ä»¥æ¥æœ€å¤§ä¸€æ¬¡ æŠ“ä½æœºä¼šå“¦ ...\n",
       "4      4  åœ£ç½—å…°å¢¨é•œç³ç‘è‰²çœŸå¥½çœ‹ã€‚å†…å®¹ï¼š#æ˜†æ˜æ’éš†åœ£ç½—å…° #è®¾è®¡æ„Ÿå¢¨é•œ #æ—¶å°šå¤ªé˜³çœ¼é•œ #æ—¶å°šæ½®æµçœ¼é•œ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **switch the cleaned df ver here\n",
    "\n",
    "cleaned_df = pd.read_csv(\"/root/ysl_project_clean/Output/cleaned_df_v2.csv\").iloc[:1000,]\n",
    "\n",
    "# ç¡®ä¿å­˜åœ¨åä¸º \"index\" çš„åˆ—ï¼ˆmake_user_message éœ€è¦ï¼‰\n",
    "cleaned_df_content = cleaned_df.reset_index(drop=False)            # ç”Ÿæˆä¸€åˆ— 'index'\n",
    "\n",
    "# åªä¿ç•™ make_user_message ç”¨åˆ°çš„ä¸¤åˆ—\n",
    "cleaned_df_content = cleaned_df_content[['index', 'title_content_hashtag_cleaned']]\n",
    "\n",
    "cleaned_df_content.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3999eee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.379 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…±æå–åˆ° 11 ä¸ªå”¯ä¸€è¯\n",
      "['å°ç‰›çš®', 'å°ç¾Šçš®', 'å½“é’±èŠ±', 'æ²¹è…Šçš®', 'æ²¹èœ¡çš®', 'çˆ†ç±³èŠ±', 'è±æ ¼çº¹', 'è°ƒæ ¼çº¹', 'é“¶è²èŠ±', 'é”¦ä¸Šæ·»èŠ±', 'é³„é±¼çš®']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "# å®šä¹‰æè´¨ç›¸å…³çš„é«˜é¢‘å…³é”®å­—\n",
    "material_keywords = [\n",
    "    \"çš®\", \"é©\", \"çº¹\", \"ç²’\", \"è”\", \"æ¼†\", \"ç»’\", \"ç£¨\", \"æŠ›å…‰\", \"å‹çº¹\", \"å‹èŠ±\",\n",
    "    \"å¸ƒ\", \"éº»\", \"æ£‰\", \"å‘¢\", \"çºº\", \"ç»‡\", \"å¸†\", \"å°¼\", \"çº±\", \"ä¸\", \"æ··çºº\", \"æ¯›\", \"å‘¢æ–™\", \"å‘¢ç»’\",\n",
    "    \"é‡‘\", \"é“¶\", \"é“¾\", \"æ‰£\", \"ç¯\", \"æ‹‰é“¾\", \"é‡‘å±\", \"äº®\", \"å“‘å…‰\", \"é’¢\", \"é“œ\", \"é•€\", \"äº”é‡‘\",\n",
    "    \"äº®é¢\", \"å…‰é¢\", \"å“‘é¢\", \"é—ª\", \"å…‰æ»‘\", \"ç²—ç³™\", \"æŸ”è½¯\", \"æŒºæ‹¬\", \"ç»†è…»\", \"çº¹ç†\",\n",
    "    \"æ‹¼\", \"æ‹¼æ¥\", \"æ‹¼è‰²\", \"æ‹¼çš®\", \"æ‹¼å¸ƒ\", \"æ··åˆ\", \"å å±‚\", \"ç»„åˆ\", \"é•¶\", \"é•¶è¾¹\", \"æ’\",\n",
    "    \"æ©¡èƒ¶\", \"ç¾Šç»’\", \"çœŸä¸\", \"è•¾ä¸\"\n",
    "]\n",
    "\n",
    "# å°†å…³é”®è¯æ‹¼æˆæ­£åˆ™è¡¨è¾¾å¼\n",
    "pattern = re.compile(\"|\".join(material_keywords))\n",
    "\n",
    "def extract_material_words(text):\n",
    "    \"\"\"æå–åŒ…å«ä»»æ„æè´¨é«˜é¢‘å­—çš„è¯æ±‡\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    \n",
    "    # åˆ†å¥ååˆ†è¯\n",
    "    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?ï¼Œ,ï¼›;ã€\\s]', text)\n",
    "    results = []\n",
    "    for sent in sentences:\n",
    "        words = jieba.lcut(sent)\n",
    "        for w in words:\n",
    "            # è¿‡æ»¤æ‰å¤ªçŸ­æˆ–å¤ªé•¿çš„è¯ï¼Œåªå–é•¿åº¦åœ¨2~6ä¹‹é—´çš„ä¸­æ–‡è¯\n",
    "            if 2 <= len(w) <= 6 and re.search(pattern, w):\n",
    "                results.append(w)\n",
    "    return results\n",
    "\n",
    "# åº”ç”¨äºæ•´ä¸ª DataFrame\n",
    "cleaned_df[\"material_terms\"] = cleaned_df[\"title_content_hashtag_cleaned\"].apply(extract_material_words)\n",
    "\n",
    "# åˆå¹¶æ‰€æœ‰ç»“æœä¸ºä¸€ä¸ªå»é‡åˆ—è¡¨\n",
    "unique_material_words = sorted(set(sum(cleaned_df[\"material_terms\"], [])))\n",
    "\n",
    "# è¾“å‡ºç»“æœ\n",
    "print(f\"å…±æå–åˆ° {len(unique_material_words)} ä¸ªå”¯ä¸€æè´¨ç›¸å…³è¯ï¼š\")\n",
    "print(unique_material_words[:200])  # å¦‚æœå¤ªé•¿ï¼Œå¯åªé¢„è§ˆå‰200ä¸ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa88e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
